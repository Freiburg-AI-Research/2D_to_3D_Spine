{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kI-St7r2u2eM"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from lib.utils.transform_3d import *\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def tensor_backto_unnormalization_image(input_image, mean, std):\n",
        "  '''\n",
        "  1. image = (image + 1) / 2.0\n",
        "  2. image = image\n",
        "  :param input_image: tensor whose size is (c,h,w) and channels is RGB\n",
        "  :param imtype: tensor type\n",
        "  :return:\n",
        "     numpy (c,h,w)\n",
        "  '''\n",
        "  if isinstance(input_image, torch.Tensor):\n",
        "    image_tensor = input_image.data\n",
        "  else:\n",
        "    return input_image\n",
        "  image = image_tensor.data.cpu().float().numpy()\n",
        "  image = image * std + mean\n",
        "  return image\n",
        "\n",
        "\n",
        "class CT_XRAY_Data_Augmentation(object):\n",
        "  def __init__(self, opt=None):\n",
        "    self.augment = List_Compose([\n",
        "      (Permute((1,0,2)), None),\n",
        "\n",
        "      (Resize_image(size=(opt.ct_channel, opt.fine_size, opt.fine_size)),\n",
        "       Resize_image(size=(opt.xray_channel, opt.fine_size, opt.fine_size))),\n",
        "\n",
        "      (Limit_Min_Max_Threshold(opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]), None),\n",
        "\n",
        "      (Normalization(opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]),\n",
        "       Normalization(opt.XRAY1_MIN_MAX[0], opt.XRAY1_MIN_MAX[1])),\n",
        "\n",
        "      (Normalization_gaussian(opt.CT_MEAN_STD[0], opt.CT_MEAN_STD[1]),\n",
        "       Normalization_gaussian(opt.XRAY1_MEAN_STD[0], opt.XRAY1_MEAN_STD[1])),\n",
        "\n",
        "      # (Get_Key_slice(opt.select_slice_num), None),\n",
        "\n",
        "      (ToTensor(), ToTensor())\n",
        "\n",
        "    ])\n",
        "\n",
        "  def __call__(self, img_list):\n",
        "    '''\n",
        "    :param img: PIL image\n",
        "    :param boxes: numpy.ndarray\n",
        "    :param labels: numpy.ndarray\n",
        "    :return:\n",
        "    '''\n",
        "    return self.augment(img_list)\n",
        "\n",
        "class CT_XRAY_Data_Test(object):\n",
        "  def __init__(self, opt=None):\n",
        "    self.augment = List_Compose([\n",
        "      (Permute((1,0,2)), None),\n",
        "\n",
        "      (Resize_image(size=(opt.ct_channel, opt.fine_size, opt.fine_size)),\n",
        "       Resize_image(size=(opt.xray_channel, opt.fine_size, opt.fine_size))),\n",
        "\n",
        "      (Limit_Min_Max_Threshold(opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]), None),\n",
        "\n",
        "      (Normalization(opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]),\n",
        "       Normalization(opt.XRAY1_MIN_MAX[0], opt.XRAY1_MIN_MAX[1])),\n",
        "\n",
        "      (Normalization_gaussian(opt.CT_MEAN_STD[0], opt.CT_MEAN_STD[1]),\n",
        "       Normalization_gaussian(opt.XRAY1_MEAN_STD[0], opt.XRAY1_MEAN_STD[1])),\n",
        "\n",
        "      # (Get_Key_slice(opt.select_slice_num), None),\n",
        "\n",
        "      (ToTensor(), ToTensor())\n",
        "\n",
        "    ])\n",
        "\n",
        "  def __call__(self, img):\n",
        "    '''\n",
        "    :param img: PIL image\n",
        "    :param boxes: numpy.ndarray\n",
        "    :param labels: numpy.ndarray\n",
        "    :return:\n",
        "    '''\n",
        "    return self.augment(img)\n",
        "\n",
        "class CT_XRAY_Data_AugmentationM(object):\n",
        "  def __init__(self, opt=None):\n",
        "    self.augment = List_Compose([\n",
        "      (Permute((1,0,2)), None),\n",
        "\n",
        "      (Resize_image(size=(opt.ct_channel, opt.resize_size, opt.resize_size)),\n",
        "       Resize_image(size=(opt.xray_channel, opt.resize_size, opt.resize_size))),\n",
        "\n",
        "      (List_Random_cropYX(size=(opt.fine_size, opt.fine_size)),),\n",
        "\n",
        "      (List_Random_mirror(2), ),\n",
        "\n",
        "      (Normalization(opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]),\n",
        "       Normalization(opt.XRAY1_MIN_MAX[0], opt.XRAY1_MIN_MAX[1])),\n",
        "\n",
        "      (Normalization_gaussian(opt.CT_MEAN_STD[0], opt.CT_MEAN_STD[1]),\n",
        "       Normalization_gaussian(opt.XRAY1_MEAN_STD[0], opt.XRAY1_MEAN_STD[1])),\n",
        "\n",
        "      # (Get_Key_slice(opt.select_slice_num), None),\n",
        "\n",
        "      (ToTensor(), ToTensor())\n",
        "\n",
        "    ])\n",
        "\n",
        "  def __call__(self, img_list):\n",
        "    '''\n",
        "    :param img: PIL image\n",
        "    :param boxes: numpy.ndarray\n",
        "    :param labels: numpy.ndarray\n",
        "    :return:\n",
        "    '''\n",
        "    return self.augment(img_list)\n",
        "\n",
        "class CT_XRAY_Data_TestM(object):\n",
        "  def __init__(self, opt=None):\n",
        "    self.augment = List_Compose([\n",
        "      (Permute((1,0,2)), None),\n",
        "\n",
        "      (Resize_image(size=(opt.ct_channel, opt.fine_size, opt.fine_size)),\n",
        "       Resize_image(size=(opt.xray_channel, opt.fine_size, opt.fine_size))),\n",
        "\n",
        "      (Normalization(opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]),\n",
        "       Normalization(opt.XRAY1_MIN_MAX[0], opt.XRAY1_MIN_MAX[1])),\n",
        "\n",
        "      (Normalization_gaussian(opt.CT_MEAN_STD[0], opt.CT_MEAN_STD[1]),\n",
        "       Normalization_gaussian(opt.XRAY1_MEAN_STD[0], opt.XRAY1_MEAN_STD[1])),\n",
        "\n",
        "      # (Get_Key_slice(opt.select_slice_num), None),\n",
        "\n",
        "      (ToTensor(), ToTensor())\n",
        "\n",
        "    ])\n",
        "\n",
        "  def __call__(self, img):\n",
        "    '''\n",
        "    :param img: PIL image\n",
        "    :param boxes: numpy.ndarray\n",
        "    :param labels: numpy.ndarray\n",
        "    :return:\n",
        "    '''\n",
        "    return self.augment(img)\n",
        "\n",
        "class CT_XRAY_Data_Augmentation_Multi(object):\n",
        "  def __init__(self, opt=None):\n",
        "    self.augment = List_Compose([\n",
        "      (Permute((1,0,2)), None, None),\n",
        "\n",
        "      (Resize_image(size=(opt.ct_channel, opt.fine_size, opt.fine_size)),\n",
        "       Resize_image(size=(opt.xray_channel, opt.fine_size, opt.fine_size)),\n",
        "       Resize_image(size=(opt.xray_channel, opt.fine_size, opt.fine_size)),),\n",
        "\n",
        "      (Limit_Min_Max_Threshold(opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]), None, None),\n",
        "\n",
        "      (Normalization(opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]),\n",
        "       Normalization(opt.XRAY1_MIN_MAX[0], opt.XRAY1_MIN_MAX[1]),\n",
        "       Normalization(opt.XRAY2_MIN_MAX[0], opt.XRAY2_MIN_MAX[1])),\n",
        "\n",
        "      (Normalization_gaussian(opt.CT_MEAN_STD[0], opt.CT_MEAN_STD[1]),\n",
        "       Normalization_gaussian(opt.XRAY1_MEAN_STD[0], opt.XRAY1_MEAN_STD[1]),\n",
        "       Normalization_gaussian(opt.XRAY2_MEAN_STD[0], opt.XRAY2_MEAN_STD[1])),\n",
        "\n",
        "      # (Get_Key_slice(opt.select_slice_num), None, None),\n",
        "\n",
        "      (ToTensor(), ToTensor(), ToTensor())\n",
        "\n",
        "    ])\n",
        "\n",
        "  def __call__(self, img_list):\n",
        "    '''\n",
        "    :param img: PIL image\n",
        "    :param boxes: numpy.ndarray\n",
        "    :param labels: numpy.ndarray\n",
        "    :return:\n",
        "    '''\n",
        "    return self.augment(img_list)\n",
        "\n",
        "class CT_XRAY_Data_Test_Multi(object):\n",
        "  def __init__(self, opt=None):\n",
        "    self.augment = List_Compose([\n",
        "      (Permute((1,0,2)), None, None),\n",
        "\n",
        "      (Resize_image(size=(opt.ct_channel, opt.fine_size, opt.fine_size)),\n",
        "       Resize_image(size=(opt.xray_channel, opt.fine_size, opt.fine_size)),\n",
        "       Resize_image(size=(opt.xray_channel, opt.fine_size, opt.fine_size)),),\n",
        "\n",
        "      (Limit_Min_Max_Threshold(opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]), None, None),\n",
        "\n",
        "      (Normalization(opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]),\n",
        "       Normalization(opt.XRAY1_MIN_MAX[0], opt.XRAY1_MIN_MAX[1]),\n",
        "       Normalization(opt.XRAY2_MIN_MAX[0], opt.XRAY2_MIN_MAX[1])),\n",
        "\n",
        "      (Normalization_gaussian(opt.CT_MEAN_STD[0], opt.CT_MEAN_STD[1]),\n",
        "       Normalization_gaussian(opt.XRAY1_MEAN_STD[0], opt.XRAY1_MEAN_STD[1]),\n",
        "       Normalization_gaussian(opt.XRAY2_MEAN_STD[0], opt.XRAY2_MEAN_STD[1])),\n",
        "\n",
        "      # (Get_Key_slice(opt.select_slice_num), None),\n",
        "\n",
        "      (ToTensor(), ToTensor(), ToTensor())\n",
        "\n",
        "    ])\n",
        "\n",
        "  def __call__(self, img):\n",
        "    '''\n",
        "    :param img: PIL image\n",
        "    :param boxes: numpy.ndarray\n",
        "    :param labels: numpy.ndarray\n",
        "    :return:\n",
        "    '''\n",
        "    return self.augment(img)\n",
        "\n",
        "\n",
        "'''\n",
        "Data Augmentation\n",
        "'''\n",
        "class CT_Data_Augmentation(object):\n",
        "  def __init__(self, opt=None):\n",
        "    self.augment = Compose([\n",
        "      Permute((1,0,2)),\n",
        "      Normalization(opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]),\n",
        "      Normalization_gaussian(opt.CT_MEAN_STD[0], opt.CT_MEAN_STD[1]),\n",
        "      Get_Key_slice(opt.select_slice_num),\n",
        "      ToTensor()\n",
        "    ])\n",
        "\n",
        "  def __call__(self, img):\n",
        "    '''\n",
        "    :param img: PIL image\n",
        "    :param boxes: numpy.ndarray\n",
        "    :param labels: numpy.ndarray\n",
        "    :return:\n",
        "    '''\n",
        "    return self.augment(img)\n",
        "\n",
        "class Xray_Data_Augmentation(object):\n",
        "  def __init__(self, opt=None):\n",
        "    self.augment = Compose([\n",
        "      Normalization(opt.XRAY1_MIN_MAX[0], opt.XRAY1_MIN_MAX[1]),\n",
        "      Normalization_gaussian(opt.XRAY1_MEAN_STD[0], opt.XRAY1_MEAN_STD[1]),\n",
        "      ToTensor()\n",
        "    ])\n",
        "\n",
        "  def __call__(self, img):\n",
        "    '''\n",
        "    :param img: PIL Image\n",
        "    :return:\n",
        "    '''\n",
        "    return self.augment(img)\n",
        "\n",
        "class CT_Data_Test(object):\n",
        "  def __init__(self, opt=None):\n",
        "    self.augment = Compose([\n",
        "      Permute((1, 0, 2)),\n",
        "      Normalization(opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]),\n",
        "      Normalization_gaussian(opt.CT_MEAN_STD[0], opt.CT_MEAN_STD[1]),\n",
        "      Get_Key_slice(opt.select_slice_num),\n",
        "      ToTensor()\n",
        "    ])\n",
        "\n",
        "  def __call__(self, img):\n",
        "    '''\n",
        "    :param img: PIL image\n",
        "    :param boxes: numpy.ndarray\n",
        "    :param labels: numpy.ndarray\n",
        "    :return:\n",
        "    '''\n",
        "    return self.augment(img)\n",
        "\n",
        "class Xray_Data_Test(object):\n",
        "  def __init__(self, opt=None):\n",
        "    self.augment = Compose([\n",
        "      Normalization(opt.XRAY1_MIN_MAX[0], opt.XRAY1_MIN_MAX[1]),\n",
        "      Normalization_gaussian(opt.XRAY1_MEAN_STD[0], opt.XRAY1_MEAN_STD[1]),\n",
        "      ToTensor()\n",
        "    ])\n",
        "\n",
        "  def __call__(self, img):\n",
        "    '''\n",
        "    :param img: PIL image\n",
        "    :param boxes: numpy.ndarray\n",
        "    :param labels: numpy.ndarray\n",
        "    :return:\n",
        "    '''\n",
        "    return self.augment(img)\n",
        "\n",
        "# ##########################################\n",
        "# Test\n",
        "# ##########################################\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U91Zj5hfu2eP"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_file = r\"C:\\Users\\Babak\\Desktop\\X-ray_to_CT_project\\X2CT\\3DGAN\\data\\LIDC-HDF5-256\\1.3.6.1.4.1.9328.50.4.0368.nii\\ct_xray_data.h5\"\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from lib.config.config import cfg, merge_dict_and_yaml\n",
        "opt = merge_dict_and_yaml(dict(), cfg)\n",
        "\n",
        "hdf = h5py.File(test_file, 'r')\n",
        "ct = np.asarray(hdf['ct'])\n",
        "xray = np.asarray(hdf['xray1'])\n",
        "xray = np.expand_dims(xray, 0)\n",
        "print(xray.shape)\n",
        "transforma = CT_XRAY_Data_Augmentation(opt)\n",
        "transform_normal = CT_XRAY_Data_Test(opt)\n",
        "ct_normal, xray_normal = transform_normal([ct, xray])\n",
        "ct_trans, xray_trans = transforma([ct, xray])\n",
        "ct_trans = tensor_backto_unnormalization_image(ct_trans, opt.CT_MEAN_STD[0], opt.CT_MEAN_STD[1])\n",
        "xray_trans = tensor_backto_unnormalization_image(xray_trans, opt.XRAY1_MEAN_STD[0], opt.XRAY1_MEAN_STD[1])\n",
        "ct_normal = tensor_backto_unnormalization_image(ct_normal, opt.CT_MEAN_STD[0], opt.CT_MEAN_STD[1])\n",
        "xray_normal = tensor_backto_unnormalization_image(xray_normal, opt.XRAY1_MEAN_STD[0], opt.XRAY1_MEAN_STD[1])\n",
        "bb = Normalization_to_range()\n",
        "ct_trans = bb(ct_trans)\n",
        "xray_trans = bb(xray_trans)\n",
        "# trans_CT = CT_Data_Augmentation(opt)\n",
        "# trans_Xray = Xray_Data_Augmentation(opt)\n",
        "# ct_trans = trans_CT(ct).numpy()\n",
        "# xray_trans = trans_Xray(xray).numpy()\n",
        "import cv2\n",
        "print(ct_trans.shape, ct_normal.shape)\n",
        "cv2.imshow('1', xray_trans[0].astype(np.uint8))\n",
        "cv2.imshow('2', ct_trans[80, :, :].astype(np.uint8))\n",
        "cv2.imshow('1-1', bb(xray_normal)[0].astype(np.uint8))\n",
        "cv2.imshow('2-1', bb(ct_normal)[80, :, :].astype(np.uint8))\n",
        "cv2.waitKey(0)\n",
        "plt.figure(1)\n",
        "plt.imshow(xray_trans[0], cmap=plt.cm.bone)\n",
        "plt.figure(2)\n",
        "plt.imshow(ct_trans[80, :, :], cmap=plt.cm.bone)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qli4k_wlu2eQ"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from lib.config.config import cfg_from_yaml, cfg, merge_dict_and_yaml, print_easy_dict\n",
        "from lib.dataset.factory import get_dataset\n",
        "from lib.model.factory import get_model\n",
        "import copy\n",
        "import torch\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "def create_args():\n",
        "    args = argparse.Namespace(\n",
        "        data='LIDC256',\n",
        "        tag='d2_multiview2500',\n",
        "        dataroot='./data/LIDC-HDF5-256',\n",
        "        dataset='train',\n",
        "        valid_dataset='test',\n",
        "        datasetfile='./data/train.txt',\n",
        "        valid_datasetfile='./data/test.txt',\n",
        "        ymlpath='./experiment/multiview2500/d2_multiview2500.yml',\n",
        "        gpuid='0',\n",
        "        dataset_class='align_ct_xray_views_std',\n",
        "        model_class='MultiViewCTGAN',\n",
        "        check_point=None,\n",
        "        load_path=None,\n",
        "        latest=False,\n",
        "        verbose=False\n",
        "    )\n",
        "    return args\n",
        "\n",
        "def main():\n",
        "  args = create_args()\n",
        "\n",
        "  # check gpu\n",
        "  if args.gpuid == '':\n",
        "    args.gpu_ids = []\n",
        "  else:\n",
        "    if torch.cuda.is_available():\n",
        "      split_gpu = str(args.gpuid).split(',')\n",
        "      args.gpu_ids = list(map(int, args.gpuid.split(',')))\n",
        "    else:\n",
        "      print('There is no gpu!')\n",
        "      exit(0)\n",
        "\n",
        "  # check point\n",
        "  if args.check_point is None:\n",
        "    args.epoch_count = 1\n",
        "  else:\n",
        "    args.epoch_count = int(args.check_point) + 1\n",
        "\n",
        "  # merge config with yaml\n",
        "  if args.ymlpath is not None:\n",
        "    cfg_from_yaml(args.ymlpath)\n",
        "  # merge config with argparse\n",
        "  opt = copy.deepcopy(cfg)\n",
        "  opt = merge_dict_and_yaml(args.__dict__, opt)\n",
        "  print_easy_dict(opt)\n",
        "\n",
        "  # add data_augmentation\n",
        "  datasetClass, augmentationClass, dataTestClass, collateClass = get_dataset(opt.dataset_class)\n",
        "  opt.data_augmentation = augmentationClass\n",
        "\n",
        "  # valid dataset\n",
        "  if args.valid_dataset is not None:\n",
        "    valid_opt = copy.deepcopy(opt)\n",
        "    valid_opt.data_augmentation = dataTestClass\n",
        "    valid_opt.datasetfile = opt.valid_datasetfile\n",
        "\n",
        "\n",
        "    valid_dataset = datasetClass(valid_opt)\n",
        "    print('Valid DataSet is {}'.format(valid_dataset.name))\n",
        "    valid_dataloader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size=1,\n",
        "      shuffle=False,\n",
        "      num_workers=int(valid_opt.nThreads),\n",
        "      collate_fn=collateClass)\n",
        "    valid_dataset_size = len(valid_dataloader)\n",
        "    print('#validation images = %d' % valid_dataset_size)\n",
        "  else:\n",
        "    valid_dataloader = None\n",
        "\n",
        "  # get dataset\n",
        "  dataset = datasetClass(opt)\n",
        "  print('DataSet is {}'.format(dataset.name))\n",
        "  dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=int(opt.nThreads),\n",
        "    collate_fn=collateClass)\n",
        "\n",
        "  dataset_size = len(dataloader)\n",
        "  print('#training images = %d' % dataset_size)\n",
        "\n",
        "  # get model\n",
        "  gan_model = get_model(opt.model_class)()\n",
        "  print('Model --{}-- will be Used'.format(gan_model.name))\n",
        "  gan_model.init_process(opt)\n",
        "  total_steps, epoch_count = gan_model.setup(opt)\n",
        "\n",
        "  # set to train\n",
        "  gan_model.train()\n",
        "\n",
        "  # visualizer\n",
        "  from lib.utils.visualizer import Visualizer\n",
        "  visualizer = Visualizer(log_dir=os.path.join(gan_model.save_root, 'train_log'))\n",
        "\n",
        "  total_steps = total_steps\n",
        "\n",
        "  # train discriminator more\n",
        "  dataloader_iter_for_discriminator = iter(dataloader)\n",
        "\n",
        "  # train\n",
        "  for epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    iter_data_time = time.time()\n",
        "\n",
        "    for epoch_i, data in enumerate(dataloader):\n",
        "      iter_start_time = time.time()\n",
        "\n",
        "      total_steps += 1\n",
        "\n",
        "      gan_model.set_input(data)\n",
        "      t0 = time.time()\n",
        "      gan_model.optimize_parameters()\n",
        "      t1 = time.time()\n",
        "\n",
        "      # if total_steps == 1:\n",
        "      #   visualizer.add_graph(model=gan_model, input=gan_model.forward())\n",
        "\n",
        "      # # visual gradient\n",
        "      # if opt.verbose and total_steps % opt.print_freq == 0:\n",
        "      #   for name, para in gan_model.named_parameters():\n",
        "      #     visualizer.add_histogram('Grad_' + name, para.grad.data.clone().cpu().numpy(), step=total_steps)\n",
        "      #     visualizer.add_histogram('Weight_' + name, para.data.clone().cpu().numpy(), step=total_steps)\n",
        "      #   for name in gan_model.model_names:\n",
        "      #     net = getattr(gan_model, 'net' + name)\n",
        "      #     if hasattr(net, 'output_dict'):\n",
        "      #       for name, out in net.output_dict.items():\n",
        "      #         visualizer.add_histogram(name, out.numpy(), step=total_steps)\n",
        "\n",
        "      # loss\n",
        "      loss_dict = gan_model.get_current_losses()\n",
        "      # visualizer.add_scalars('Train_Loss', loss_dict, step=total_steps)\n",
        "      total_loss = visualizer.add_total_scalar('Total loss', loss_dict, step=total_steps)\n",
        "      # visualizer.add_average_scalers('Epoch Loss', loss_dict, step=total_steps, write=False)\n",
        "      # visualizer.add_average_scalar('Epoch total Loss', total_loss)\n",
        "\n",
        "      # metrics\n",
        "      # metrics_dict = gan_model.get_current_metrics()\n",
        "      # visualizer.add_scalars('Train_Metrics', metrics_dict, step=total_steps)\n",
        "      # visualizer.add_average_scalers('Epoch Metrics', metrics_dict, step=total_steps, write=False)\n",
        "\n",
        "      if total_steps % opt.print_freq == 0:\n",
        "        print('total step: {} timer: {:.4f} sec.'.format(total_steps, t1 - t0))\n",
        "        print('epoch {}/{}, step{}:{} || total loss:{:.4f}'.format(epoch, opt.niter + opt.niter_decay,\n",
        "                                                                   epoch_i, dataset_size, total_loss))\n",
        "        print('||'.join(['{}: {:.4f}'.format(k, v) for k, v in loss_dict.items()]))\n",
        "        # print('||'.join(['{}: {:.4f}'.format(k, v) for k, v in metrics_dict.items()]))\n",
        "        print('')\n",
        "\n",
        "      # if total_steps % opt.print_img_freq == 0:\n",
        "      #   visualizer.add_image('Image', gan_model.get_current_visuals(), gan_model.get_normalization_list(), total_steps)\n",
        "\n",
        "      '''\n",
        "      WGAN\n",
        "      '''\n",
        "      if (opt.critic_times - 1) > 0:\n",
        "        for critic_i in range(opt.critic_times - 1):\n",
        "          try:\n",
        "            data = next(dataloader_iter_for_discriminator)\n",
        "            gan_model.set_input(data)\n",
        "            gan_model.optimize_D()\n",
        "          except:\n",
        "            dataloader_iter_for_discriminator = iter(dataloader)\n",
        "      del(loss_dict)\n",
        "\n",
        "    # # save model every epoch\n",
        "    # print('saving the latest model (epoch %d, total_steps %d)' %\n",
        "    #       (epoch, total_steps))\n",
        "    # gan_model.save_networks(epoch, total_steps, True)\n",
        "\n",
        "    # save model several epoch\n",
        "    if epoch % opt.save_epoch_freq == 0 and epoch >= opt.begin_save_epoch:\n",
        "      print('saving the model at the end of epoch %d, iters %d' %\n",
        "            (epoch, total_steps))\n",
        "      gan_model.save_networks(epoch, total_steps)\n",
        "\n",
        "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
        "          (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
        "    ##########\n",
        "    # For speed\n",
        "    ##########\n",
        "    # visualizer.add_image('Image_Epoch', gan_model.get_current_visuals(), gan_model.get_normalization_list(), epoch)\n",
        "    # visualizer.add_average_scalers('Epoch Loss', None, step=epoch, write=True)\n",
        "    # visualizer.add_average_scalar('Epoch total Loss', None, step=epoch, write=True)\n",
        "\n",
        "    # visualizer.add_average_scalers('Epoch Metrics', None, step=epoch, write=True)\n",
        "\n",
        "    # visualizer.add_scalar('Learning rate', gan_model.optimizers[0].param_groups[0]['lr'], epoch)\n",
        "    gan_model.update_learning_rate(epoch)\n",
        "\n",
        "    # # Test\n",
        "    # if args.valid_dataset is not None:\n",
        "    #   if epoch % opt.save_epoch_freq == 0 or epoch==1:\n",
        "    #     gan_model.eval()\n",
        "    #     iter_valid_dataloader = iter(valid_dataloader)\n",
        "    #     for v_i in range(len(valid_dataloader)):\n",
        "    #       data = next(iter_valid_dataloader)\n",
        "    #       gan_model.set_input(data)\n",
        "    #       gan_model.test()\n",
        "    #\n",
        "    #       if v_i < opt.howmany_in_train:\n",
        "    #         visualizer.add_image('Test_Image', gan_model.get_current_visuals(), gan_model.get_normalization_list(), epoch*10+v_i, max_image=25)\n",
        "    #\n",
        "    #       # metrics\n",
        "    #       metrics_dict = gan_model.get_current_metrics()\n",
        "    #       visualizer.add_average_scalers('Epoch Test_Metrics', metrics_dict, step=total_steps, write=False)\n",
        "    #     visualizer.add_average_scalers('Epoch Test_Metrics', None, step=epoch, write=True)\n",
        "    #\n",
        "    #     gan_model.train()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tj3MSsUu2eR"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from lib.config.config import cfg_from_yaml, cfg, merge_dict_and_yaml, print_easy_dict\n",
        "from lib.dataset.factory import get_dataset\n",
        "from lib.model.factory import get_model\n",
        "from lib.utils import html\n",
        "from lib.utils.visualizer import tensor_back_to_unnormalization, save_images, tensor_back_to_unMinMax\n",
        "#from lib.utils.metrics_np import MAE, MSE, Peak_Signal_to_Noise_Rate, Structural_Similarity, Cosine_Similarity\n",
        "from lib.utils import ct as CT\n",
        "import copy\n",
        "import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class Args:\n",
        "    pass\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  if __name__ == '__main__':\n",
        "    # args = parse_args()\n",
        "    args = Args()\n",
        "    args.data = 'LIDC256'\n",
        "    args.tag = 'd2_multiview2500'\n",
        "    args.dataroot = './data/LIDC-HDF5-256'\n",
        "    args.dataset = 'test'\n",
        "    args.datasetfile = './data/test.txt'\n",
        "    args.ymlpath = './experiment/multiview2500/d2_multiview2500.yml'\n",
        "    args.gpuid = '0'\n",
        "    args.dataset_class = 'align_ct_xray_views_std'\n",
        "    args.model_class = 'MultiViewCTGAN'\n",
        "    args.check_point = '100'\n",
        "    args.latest = False\n",
        "    args.verbose = False\n",
        "    args.load_path = None\n",
        "    args.how_many = 50\n",
        "    args.resultdir = './results'\n",
        "\n",
        "\n",
        "  # check gpu\n",
        "  if args.gpuid == '':\n",
        "    args.gpu_ids = []\n",
        "  else:\n",
        "    if torch.cuda.is_available():\n",
        "      split_gpu = str(args.gpuid).split(',')\n",
        "      args.gpu_ids = [int(i) for i in split_gpu]\n",
        "    else:\n",
        "      print('There is no gpu!')\n",
        "      exit(0)\n",
        "\n",
        "  # check point\n",
        "  if args.check_point is None:\n",
        "    args.epoch_count = 1\n",
        "  else:\n",
        "    args.epoch_count = int(args.check_point)\n",
        "\n",
        "  # merge config with yaml\n",
        "  if args.ymlpath is not None:\n",
        "    cfg_from_yaml(args.ymlpath)\n",
        "  # merge config with argparse\n",
        "  opt = copy.deepcopy(cfg)\n",
        "  opt = merge_dict_and_yaml(args.__dict__, opt)\n",
        "  print_easy_dict(opt)\n",
        "\n",
        "  opt.serial_batches = True\n",
        "\n",
        "  # add data_augmentation\n",
        "  datasetClass, _, dataTestClass, collateClass = get_dataset(opt.dataset_class)\n",
        "  opt.data_augmentation = dataTestClass\n",
        "\n",
        "  # get dataset\n",
        "  dataset = datasetClass(opt)\n",
        "  print('DataSet is {}'.format(dataset.name))\n",
        "  dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=int(opt.nThreads),\n",
        "    collate_fn=collateClass)\n",
        "\n",
        "  dataset_size = len(dataloader)\n",
        "  print('#Test images = %d' % dataset_size)\n",
        "\n",
        "  # get model\n",
        "  gan_model = get_model(opt.model_class)()\n",
        "  print('Model --{}-- will be Used'.format(gan_model.name))\n",
        "\n",
        "  # set to test\n",
        "  gan_model.eval()\n",
        "\n",
        "  gan_model.init_process(opt)\n",
        "  total_steps, epoch_count = gan_model.setup(opt)\n",
        "\n",
        "  # must set to test Mode again, due to  omission of assigning mode to network layers\n",
        "  # model.training is test, but BN.training is training\n",
        "  if opt.verbose:\n",
        "    print('## Model Mode: {}'.format('Training' if gan_model.training else 'Testing'))\n",
        "    for i, v in gan_model.named_modules():\n",
        "      print(i, v.training)\n",
        "\n",
        "  if 'batch' in opt.norm_G:\n",
        "    gan_model.eval()\n",
        "  elif 'instance' in opt.norm_G:\n",
        "    gan_model.eval()\n",
        "    # instance norm in training mode is better\n",
        "    for name, m in gan_model.named_modules():\n",
        "      if m.__class__.__name__.startswith('InstanceNorm'):\n",
        "        m.train()\n",
        "  else:\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  if opt.verbose:\n",
        "    print('## Change to Model Mode: {}'.format('Training' if gan_model.training else 'Testing'))\n",
        "    for i, v in gan_model.named_modules():\n",
        "      print(i, v.training)\n",
        "\n",
        "  web_dir = os.path.join(opt.resultdir, opt.data, '%s_%s' % (opt.dataset, opt.check_point))\n",
        "  webpage = html.HTML(web_dir, 'Experiment = %s, Phase = %s, Epoch = %s' % (opt.data, opt.dataset, opt.check_point))\n",
        "  ctVisual = CT.CTVisual()\n",
        "\n",
        "  avg_dict = dict()\n",
        "  for epoch_i, data in tqdm.tqdm(enumerate(dataloader)):\n",
        "\n",
        "    gan_model.set_input(data)\n",
        "    gan_model.test()\n",
        "\n",
        "    visuals = gan_model.get_current_visuals()\n",
        "    img_path = gan_model.get_image_paths()\n",
        "\n",
        "    if epoch_i <= opt.how_many:\n",
        "      #\n",
        "      # Image HTML\n",
        "      #\n",
        "      save_images(webpage, visuals, img_path, gan_model.get_normalization_list(), max_image=50)\n",
        "      #\n",
        "      # CT Source\n",
        "      #\n",
        "      generate_CT = visuals['G_fake'].data.clone().cpu().numpy()\n",
        "      real_CT = visuals['G_real'].data.clone().cpu().numpy()\n",
        "      # To NDHW\n",
        "      if 'std' in opt.dataset_class or 'baseline' in opt.dataset_class:\n",
        "        generate_CT_transpose = generate_CT\n",
        "        real_CT_transpose = real_CT\n",
        "      else:\n",
        "        generate_CT_transpose = np.transpose(generate_CT, (0, 2, 1, 3))\n",
        "        real_CT_transpose = np.transpose(real_CT, (0, 2, 1, 3))\n",
        "      # Inveser Deepth\n",
        "      generate_CT_transpose = generate_CT_transpose[:, ::-1, :, :]\n",
        "      real_CT_transpose = real_CT_transpose[:, ::-1, :, :]\n",
        "      # To [0, 1]\n",
        "      generate_CT_transpose = tensor_back_to_unnormalization(generate_CT_transpose, opt.CT_MEAN_STD[0],\n",
        "                                                             opt.CT_MEAN_STD[1])\n",
        "      real_CT_transpose = tensor_back_to_unnormalization(real_CT_transpose, opt.CT_MEAN_STD[0], opt.CT_MEAN_STD[1])\n",
        "      # Clip generate_CT\n",
        "      generate_CT_transpose = np.clip(generate_CT_transpose, 0, 1)\n",
        "\n",
        "      # #\n",
        "      # # Evaluate Part\n",
        "      # #\n",
        "      # mae = MAE(real_CT_transpose, generate_CT_transpose, size_average=False)\n",
        "      # mse = MSE(real_CT_transpose, generate_CT_transpose, size_average=False)\n",
        "      # cosinesimilarity = Cosine_Similarity(real_CT_transpose, generate_CT_transpose, size_average=False)\n",
        "      # psnr = Peak_Signal_to_Noise_Rate(real_CT_transpose, generate_CT_transpose, size_average=False, PIXEL_MAX=1.0)\n",
        "      # ssim = Structural_Similarity(real_CT_transpose, generate_CT_transpose, size_average=False, PIXEL_MAX=1.0)\n",
        "      #\n",
        "      # metrics_list = [('MAE', mae), ('MSE', mse), ('CosineSimilarity', cosinesimilarity), ('PSNR-1', psnr[0]),\n",
        "      #                 ('PSNR-2', psnr[1]), ('PSNR-3', psnr[2]), ('PSNR-avg', psnr[3]),\n",
        "      #                 ('SSIM-1', ssim[0]), ('SSIM-2', ssim[1]), ('SSIM-3', ssim[2]), ('SSIM-avg', ssim[3])]\n",
        "\n",
        "      # To HU coordinate\n",
        "      generate_CT_transpose = tensor_back_to_unMinMax(generate_CT_transpose, opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]).astype(np.int32) - 1024\n",
        "      real_CT_transpose = tensor_back_to_unMinMax(real_CT_transpose, opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]).astype(np.int32) - 1024\n",
        "      # Save\n",
        "      name1 = os.path.splitext(os.path.basename(img_path[0][0]))[0]\n",
        "      name2 = os.path.split(os.path.dirname(img_path[0][0]))[-1]\n",
        "      name = name2 + '_' + name1\n",
        "      image_root = os.path.join(web_dir, 'CT', name)\n",
        "      if not os.path.exists(image_root):\n",
        "        os.makedirs(image_root)\n",
        "      save_path = os.path.join(image_root, 'fake_ct.mha')\n",
        "      ctVisual.save(generate_CT_transpose.squeeze(0), spacing=(1.0, 1.0, 1.0), origin=(0,0,0), path=save_path)\n",
        "      save_path = os.path.join(image_root, 'real_ct.mha')\n",
        "      ctVisual.save(real_CT_transpose.squeeze(0), spacing=(1.0, 1.0, 1.0), origin=(0, 0, 0), path=save_path)\n",
        "\n",
        "    else:\n",
        "      break\n",
        "    del visuals, img_path\n",
        "  webpage.save()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJYZuN3tu2eS"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from lib.config.config import cfg_from_yaml, cfg, merge_dict_and_yaml, print_easy_dict\n",
        "from lib.dataset.factory import get_dataset\n",
        "from lib.model.factory import get_model\n",
        "from lib.utils.visualizer import tensor_back_to_unnormalization, tensor_back_to_unMinMax\n",
        "from lib.utils.metrics_np import MAE, MSE, Peak_Signal_to_Noise_Rate, Structural_Similarity, Cosine_Similarity, \\\n",
        "  Peak_Signal_to_Noise_Rate_3D\n",
        "import copy\n",
        "import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "class Args:\n",
        "    pass\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  if __name__ == '__main__':\n",
        "    # args = parse_args()\n",
        "    args = Args()\n",
        "    args.data = 'LIDC256'\n",
        "    args.tag = 'd2_multiview2500'\n",
        "    args.dataroot = './data/LIDC-HDF5-256'\n",
        "    args.dataset = 'test'\n",
        "    args.datasetfile = './data/test.txt'\n",
        "    args.ymlpath = './experiment/multiview2500/d2_multiview2500.yml'\n",
        "    args.gpuid = '0'\n",
        "    args.dataset_class = 'align_ct_xray_views_std'\n",
        "    args.model_class = 'MultiViewCTGAN'\n",
        "    args.check_point = '100'\n",
        "    args.latest = False\n",
        "    args.verbose = False\n",
        "    args.load_path = None\n",
        "    args.how_many = 50\n",
        "    args.resultdir = './multiview'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(args):\n",
        "  # check gpu\n",
        "  if args.gpuid == '':\n",
        "    args.gpu_ids = []\n",
        "  else:\n",
        "    if torch.cuda.is_available():\n",
        "      split_gpu = str(args.gpuid).split(',')\n",
        "      args.gpu_ids = [int(i) for i in split_gpu]\n",
        "    else:\n",
        "      print('There is no gpu!')\n",
        "      exit(0)\n",
        "\n",
        "  # check point\n",
        "  if args.check_point is None:\n",
        "    args.epoch_count = 1\n",
        "  else:\n",
        "    args.epoch_count = int(args.check_point)\n",
        "\n",
        "  # merge config with yaml\n",
        "  if args.ymlpath is not None:\n",
        "    cfg_from_yaml(args.ymlpath)\n",
        "  # merge config with argparse\n",
        "  opt = copy.deepcopy(cfg)\n",
        "  opt = merge_dict_and_yaml(args.__dict__, opt)\n",
        "  print_easy_dict(opt)\n",
        "\n",
        "  opt.serial_batches = True\n",
        "\n",
        "  # add data_augmentation\n",
        "  datasetClass, _, dataTestClass, collateClass = get_dataset(opt.dataset_class)\n",
        "  opt.data_augmentation = dataTestClass\n",
        "\n",
        "  # get dataset\n",
        "  dataset = datasetClass(opt)\n",
        "  print('DataSet is {}'.format(dataset.name))\n",
        "  dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=int(opt.nThreads),\n",
        "    collate_fn=collateClass)\n",
        "\n",
        "  dataset_size = len(dataloader)\n",
        "  print('#Test images = %d' % dataset_size)\n",
        "\n",
        "  # get model\n",
        "  gan_model = get_model(opt.model_class)()\n",
        "  print('Model --{}-- will be Used'.format(gan_model.name))\n",
        "\n",
        "  # set to test\n",
        "  gan_model.eval()\n",
        "\n",
        "  gan_model.init_process(opt)\n",
        "  total_steps, epoch_count = gan_model.setup(opt)\n",
        "\n",
        "  # must set to test Mode again, due to  omission of assigning mode to network layers\n",
        "  # model.training is test, but BN.training is training\n",
        "  if opt.verbose:\n",
        "    print('## Model Mode: {}'.format('Training' if gan_model.training else 'Testing'))\n",
        "    for i, v in gan_model.named_modules():\n",
        "      print(i, v.training)\n",
        "\n",
        "  if 'batch' in opt.norm_G:\n",
        "    gan_model.eval()\n",
        "  elif 'instance' in opt.norm_G:\n",
        "    gan_model.eval()\n",
        "    # instance norm in training mode is better\n",
        "    for name, m in gan_model.named_modules():\n",
        "      if m.__class__.__name__.startswith('InstanceNorm'):\n",
        "        m.train()\n",
        "  else:\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  if opt.verbose:\n",
        "    print('## Change to Model Mode: {}'.format('Training' if gan_model.training else 'Testing'))\n",
        "    for i, v in gan_model.named_modules():\n",
        "      print(i, v.training)\n",
        "\n",
        "  result_dir = os.path.join(opt.resultdir, opt.data, '%s_%s' % (opt.dataset, opt.check_point))\n",
        "  if not os.path.exists(result_dir):\n",
        "    os.makedirs(result_dir)\n",
        "\n",
        "  avg_dict = dict()\n",
        "  for epoch_i, data in tqdm.tqdm(enumerate(dataloader)):\n",
        "\n",
        "    gan_model.set_input(data)\n",
        "    gan_model.test()\n",
        "\n",
        "    visuals = gan_model.get_current_visuals()\n",
        "    img_path = gan_model.get_image_paths()\n",
        "\n",
        "    #\n",
        "    # Evaluate Part\n",
        "    #\n",
        "    generate_CT = visuals['G_fake'].data.clone().cpu().numpy()\n",
        "    real_CT = visuals['G_real'].data.clone().cpu().numpy()\n",
        "    # To [0, 1]\n",
        "    # To NDHW\n",
        "    if 'std' in opt.dataset_class or 'baseline' in opt.dataset_class:\n",
        "      generate_CT_transpose = generate_CT\n",
        "      real_CT_transpose = real_CT\n",
        "    else:\n",
        "      generate_CT_transpose = np.transpose(generate_CT, (0, 2, 1, 3))\n",
        "      real_CT_transpose = np.transpose(real_CT, (0, 2, 1, 3))\n",
        "    generate_CT_transpose = tensor_back_to_unnormalization(generate_CT_transpose, opt.CT_MEAN_STD[0],\n",
        "                                                           opt.CT_MEAN_STD[1])\n",
        "    real_CT_transpose = tensor_back_to_unnormalization(real_CT_transpose, opt.CT_MEAN_STD[0], opt.CT_MEAN_STD[1])\n",
        "    # clip generate_CT\n",
        "    generate_CT_transpose = np.clip(generate_CT_transpose, 0, 1)\n",
        "\n",
        "    # CT range 0-1\n",
        "    mae0 = MAE(real_CT_transpose, generate_CT_transpose, size_average=False)\n",
        "    mse0 = MSE(real_CT_transpose, generate_CT_transpose, size_average=False)\n",
        "    cosinesimilarity = Cosine_Similarity(real_CT_transpose, generate_CT_transpose, size_average=False)\n",
        "    ssim = Structural_Similarity(real_CT_transpose, generate_CT_transpose, size_average=False, PIXEL_MAX=1.0)\n",
        "    # CT range 0-4096\n",
        "    generate_CT_transpose = tensor_back_to_unMinMax(generate_CT_transpose, opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]).astype(\n",
        "      np.int32)\n",
        "    real_CT_transpose = tensor_back_to_unMinMax(real_CT_transpose, opt.CT_MIN_MAX[0], opt.CT_MIN_MAX[1]).astype(\n",
        "      np.int32)\n",
        "    psnr_3d = Peak_Signal_to_Noise_Rate_3D(real_CT_transpose, generate_CT_transpose, size_average=False, PIXEL_MAX=4095)\n",
        "    psnr = Peak_Signal_to_Noise_Rate(real_CT_transpose, generate_CT_transpose, size_average=False, PIXEL_MAX=4095)\n",
        "    mae = MAE(real_CT_transpose, generate_CT_transpose, size_average=False)\n",
        "    mse = MSE(real_CT_transpose, generate_CT_transpose, size_average=False)\n",
        "\n",
        "    name1 = os.path.splitext(os.path.basename(img_path[0][0]))[0]\n",
        "    name2 = os.path.split(os.path.dirname(img_path[0][0]))[-1]\n",
        "    name = name2 + '_' + name1\n",
        "    print(cosinesimilarity, name)\n",
        "    if cosinesimilarity is np.nan or cosinesimilarity > 1:\n",
        "      print(os.path.splitext(os.path.basename(gan_model.get_image_paths()[0][0]))[0])\n",
        "      continue\n",
        "\n",
        "    metrics_list = [('MAE0', mae0), ('MSE0', mse0), ('MAE', mae), ('MSE', mse), ('CosineSimilarity', cosinesimilarity),\n",
        "                    ('psnr-3d', psnr_3d), ('PSNR-1', psnr[0]),\n",
        "                    ('PSNR-2', psnr[1]), ('PSNR-3', psnr[2]), ('PSNR-avg', psnr[3]),\n",
        "                    ('SSIM-1', ssim[0]), ('SSIM-2', ssim[1]), ('SSIM-3', ssim[2]), ('SSIM-avg', ssim[3])]\n",
        "\n",
        "    for key, value in metrics_list:\n",
        "      if avg_dict.get(key) is None:\n",
        "        avg_dict[key] = [] + value.tolist()\n",
        "      else:\n",
        "        avg_dict[key].extend(value.tolist())\n",
        "\n",
        "    del visuals, img_path\n",
        "\n",
        "  for key, value in avg_dict.items():\n",
        "    print('### --{}-- total: {}; avg: {} '.format(key, len(value), np.round(np.mean(value), 7)))\n",
        "    avg_dict[key] = np.mean(value)\n",
        "\n",
        "  return avg_dict\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  evaluate(args)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "itk_build2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}